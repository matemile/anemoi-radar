defaults:
- data: zarr
- dataloader: native_grid
- diagnostics: evaluation
- hardware: slurm
- graph: multi_scale
- model: graphtransformer
- training: default
- override hydra/hydra_logging: disabled
- override hydra/job_logging: disabled
- _self_

hydra:
  output_subdir: null
  run:
    dir: .

dataloader:
  num_workers:
    training: 1
    validation: 1
    test: 1
    predict: 1
  batch_size:
    training: 1
    validation: 1
    test: 1
    predict: 1

  dataset:
    dataset: ${hardware.paths.data}/${hardware.files.dataset}

  limit_batches: 
    training: null
    validation: null
  training:
    start: 2020-11-13
    end: 2024-11-13
    dataset: ${dataloader.dataset} 
    frequency: 1
    drop: ["block_percent", "is_blocked", "is_nodata"]
  validation:
    start: 2024-11-14
    end: 2025-04-13
    dataset: ${dataloader.dataset}
    frequency: 1
    drop: ["block_percent", "is_blocked", "is_nodata"]
  test:
    start: 2025-04-13
    end: 2025-04-13
    dataset: ${dataloader.dataset}
    frequency: 1
    drop: ["block_percent", "is_blocked", "is_nodata"]

hardware:
  num_gpus_per_node: 8
  num_gpus_per_model: 1
  accelerator: auto
  paths:
    data: /pfs/lustrep3/scratch/project_465002262/milemate/datasets/ 
    output: /pfs/lustrep3/scratch/project_465002262/milemate/experiments/radar_imputer/ 
    graph: /pfs/lustrep3/scratch/project_465002262/milemate/graphs/
  files:
    dataset: radar-nordic-2020-2025-15m-v20.zarr
    graph: graph-radar-nordicllc.pt
    warm_start: null #specific checkpoint to start from, defaults to last.ckpt

diagnostics:
  plot: 
    callbacks: []
  log:
    mlflow:
      enabled: True
      offline: True
      authentication: True
      experiment_name: 'metno_radar'
      tracking_uri: https://mlflow.ecmwf.int
      run_name: radar_imputer
  print_memory_summary: True

# Set clobber: False and specify the correct path and file in hardware to load graph, the path below is 
# only used for saving graphs.
graph:
  overwrite: False
  nodes:
    data: 
      node_builder:
        _target_: anemoi.graphs.nodes.ZarrDatasetNodes # options: ZarrDatasetNodes, NPZFileNodes
        dataset: ${dataloader.training.dataset}
      attributes:
        area_weight:
          _target_: anemoi.graphs.nodes.attributes.UniformWeights
          norm: unit-max
    hidden:
      node_builder:
        _target_: anemoi.graphs.nodes.LimitedAreaTriNodes # options: ZarrDatasetNodes, NPZFileNodes, TriNodes
        resolution: 7 # grid resolution for npz (o32, o48, ...)
        reference_node_name: ${graph.data}

  #mulig dette kan fjernes
  edges:
    # Encoder configuration
    - source_name: ${graph.data}
      target_name: ${graph.hidden}
      edge_builders:
      - _target_: anemoi.graphs.edges.CutOffEdges # options: KNNEdges, CutOffEdges
        cutoff_factor: 0.6 # only for cutoff method
      attributes: ${graph.attributes.edges}
      #Â Processor configuration
    - source_name: ${graph.hidden}
      target_name: ${graph.hidden}
      edge_builders:
      - _target_: anemoi.graphs.edges.MultiScaleEdges
        x_hops: 1
      attributes: ${graph.attributes.edges}
      # Decoder configuration
    - source_name: ${graph.hidden}
      target_name: ${graph.data}
      edge_builders:
      - _target_: anemoi.graphs.edges.KNNEdges # options: KNNEdges, CutOffEdges
        num_nearest_neighbours: 3 # only for knn method
      attributes: ${graph.attributes.edges}

graphs:
  output_path: ${hardware.paths.graph}${hardware.files.graph}
  save_graph_plots: False
  clobber: False

data:
  resolution: o96
  frequency: 15m
  timestep: 15m
  format: zarr
  forcing: []

  diagnostic: []

  remapped:

  normalizer:
    default: "mean-std"
    std: [lwe_precipitation_rate]

    min-max:
    max: []
    none: []

  imputer:
    default: "none"
    0:
      - lwe_precipitation_rate

  remapper:
    default: "none"

  processors:

    imputer:
      _target_: anemoi.models.preprocessing.imputer.DynamicConstantImputer
      _convert_: all
      config: ${data.imputer}

    normalizer:
      _target_: anemoi.models.preprocessing.normalizer.InputNormalizer
      _convert_: all
      config: ${data.normalizer}

  # Values set in the code
  num_features: null # number of features in the forecast state


model:
  processor:
    num_layers: 8 # will make model shit, but ok for testing
  num_channels: 80
  trainable_parameters:
    data: 0
    hidden: 0
    data2hidden: 0
    hidden2data: 0
    hidden2hidden: 0 # GNN and GraphTransformer Processor only
  bounding: #These are applied in order
    - _target_: anemoi.models.layers.bounding.ReluBounding #[0, infinity)
      variables: [lwe_precipitation_rate
      ]

training:
  run_id: null #path to store the experiment in with output_base as root, null for random name, =fork_run_id to continue training in the same folder.
  fork_run_id: null #path to the experiment to fork from with output_base as root
  load_weights_only: False #loads entire model if False, loads only weights if True
  max_epochs: null
  max_steps: 20000
  lr:
    rate: 6.25e-5
    min: 3.0e-7
  multistep_input: 4
  rollout:
    start: 4
    epoch_increment: 0
    max: 4
